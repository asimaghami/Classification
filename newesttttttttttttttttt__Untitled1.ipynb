{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow-probability\n",
        "!pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_-rO8PatQJg",
        "outputId": "a942d929-098e-4269-8d60-b4d661af8761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n"
      ],
      "metadata": {
        "id": "8TiBfvKr4lxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "#data = pd.read_csv('https://raw.githubusercontent.com/harpreetSinghGuller/Data-Science-R/master/SAHeart.csv')\n",
        "df = pd.read_csv(\"SAHeart.csv\")\n",
        "df[\"famhist\"] = df[\"famhist\"].map({\"Absent\": 0, \"Present\": 1})\n",
        "\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = df.drop('chd', axis=1)\n",
        "y = df['chd']\n",
        "\n",
        "# Drop any missing values\n",
        "##df.dropna(inplace=True)\n",
        "\n",
        "\n",
        "# Normalize the features\n",
        "## X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "GXLldC2GrbHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "hu4C5Dp52nRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the inputs to the expected data type\n",
        "X_train = tf.cast(X_train, tf.float32)\n",
        "y_train = tf.cast(y_train, tf.float32)\n",
        "X_test = tf.cast(X_test, tf.float32)\n",
        "y_test = tf.cast(y_test, tf.float32)"
      ],
      "metadata": {
        "id": "rsxQ1MTQaSRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors"
      ],
      "metadata": {
        "id": "0Mh4Bx6RadPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 10\n",
        "my_bijects = []\n",
        "ndim = 11  # Adjust this to match the number of features in your dataset\n",
        "\n",
        "zdist = tfd.MultivariateNormalDiag(loc=[0.0] * ndim)\n",
        "\n",
        "# loop over desired bijectors and put into list\n",
        "for i in range(num_layers):\n",
        "    # Syntax to make a MAF\n",
        "    anet = tfb.AutoregressiveNetwork(\n",
        "        params=ndim, hidden_units=[128, 128], activation=\"relu\"\n",
        "    )\n",
        "    ab = tfb.MaskedAutoregressiveFlow(anet)\n",
        "    # Add bijector to list\n",
        "    my_bijects.append(ab)\n",
        "    # Now permuate (!important!)\n",
        "    permute = tfb.Permute(list(range(ndim-1, -1, -1)))  # Adjust this to match the number of features in your dataset\n",
        "    my_bijects.append(permute)\n",
        "\n",
        "# put all bijectors into one \"chain bijector\"\n",
        "# that looks like one\n",
        "big_bijector = tfb.Chain(my_bijects)\n",
        "\n",
        "# make transformed dist\n",
        "td = tfd.TransformedDistribution(zdist, bijector=big_bijector)"
      ],
      "metadata": {
        "id": "K7CFh2BTad8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the loss function\n",
        "negloglik = lambda y, rv_y: -rv_y.log_prob(y)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(9),\n",
        "  tfp.layers.DistributionLambda(lambda t: tfd.Normal(loc=t[..., :1],\n",
        "                                                     scale=1e-5 + tf.math.softplus(0.05 * t[...,1:]))),\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=negloglik)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, verbose=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAfNk4OdarTq",
        "outputId": "fe4bb600-813c-4082-918e-1d7eca642655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d5f022424d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_zYFmkMauCy",
        "outputId": "ee66ec60-f171-4383-878d-9c7fd495bf89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 0.6897\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6896783709526062"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSHeXziSaukg",
        "outputId": "92c46b35-54cd-4859-fc95-c3ec3b8b3889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y = df['chd']\n",
        "# Convert the predictions to binary format\n",
        "y_pred_binary = [1 if y > 0.5 else 0 for y in y_pred]\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(y_test, y_pred_binary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G7XnzOIawKi",
        "outputId": "a9c5874c-bb0b-4060-88cb-060e7f8dc13a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.86      0.79        59\n",
            "         1.0       0.65      0.44      0.53        34\n",
            "\n",
            "    accuracy                           0.71        93\n",
            "   macro avg       0.69      0.65      0.66        93\n",
            "weighted avg       0.70      0.71      0.69        93\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-2mZiNudaruR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gaussian Mixture Model (GMM)\n",
        "gmm = GaussianMixture(n_components=5)\n",
        "gmm.fit(X_train_scaled)\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "svm = SVC()\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Logistic Regression (LR)\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Random Forest (RF)\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# MLP (Multi-Layer Perceptron)\n",
        "mlp = MLPClassifier()\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "\n",
        "# XGBoost\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "xgb_model.fit(X_train_scaled, y_train)\n"
      ],
      "metadata": {
        "id": "awiAK2i5XWuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate accuracy\n",
        "models = {\n",
        "    \"GMM\": gmm,\n",
        "    \"SVM\": svm,\n",
        "    \"LR\": lr,\n",
        "    \"RF\": rf,\n",
        "    \"MLP\": mlp,\n",
        "    \"XGBoost\": xgb_model\n",
        "}\n",
        "\n",
        "accuracies = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    if model_name == \"LDA\":\n",
        "        X_test_transformed = model.transform(X_test_scaled)\n",
        "    else:\n",
        "        X_test_transformed = X_test_scaled\n",
        "    y_pred = model.predict(X_test_transformed)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies[model_name] = accuracy\n",
        "\n",
        "# Print accuracies\n",
        "for model_name, accuracy in accuracies.items():\n",
        "    print(f\"{model_name}: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmygziiHXZCe",
        "outputId": "6fae2a06-d641-4db8-d2c1-956979c369b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GMM: 0.6129032258064516\n",
            "SVM: 0.7526881720430108\n",
            "LR: 0.7849462365591398\n",
            "RF: 0.7096774193548387\n",
            "MLP: 0.7419354838709677\n",
            "XGBoost: 0.7096774193548387\n"
          ]
        }
      ]
    }
  ]
}